# ğŸŒ¦ï¸ Webscraping Climatempo â€” Pipeline Completo com Airflow + DBT

Projeto de engenharia de dados que coleta previsÃµes meteorolÃ³gicas via **web scraping**, estrutura os dados em arquitetura medalhÃ£o (Bronze â†’ Silver â†’ Gold) e avalia a **qualidade das previsÃµes** comparando previsÃ£o D-1 vs dado real D.

Toda a pipeline Ã© **orquestrada com Apache Airflow**.

---

# ğŸ¯ Objetivo do Projeto

Construir um pipeline automatizado capaz de:

* Coletar previsÃµes do tempo do site Climatempo
* Armazenar os dados brutos
* Transformar e modelar os dados com DBT
* Comparar previsÃ£o vs dado real
* Calcular mÃ©tricas de erro (MAE, RMSE, Bias, MAPE)
* Gerar ranking de precisÃ£o por cidade

O foco principal Ã© **medir o quÃ£o precisa Ã© a previsÃ£o do tempo.**

---

# ğŸ—ï¸ Arquitetura do Projeto

```
Scrapy â†’ Transform â†’ Bronze (CSV)
                â†“
              DBT
      Silver â†’ Gold (SQLite)
                â†“
             Airflow
                â†“
           Dashboard (Streamlit)
```

---

# ğŸ¥‰ Camada Bronze

A Bronze Ã© dividida em **duas tarefas principais**:

## 1ï¸âƒ£ Scrapy (Web Scraping)

ResponsÃ¡vel por:

* Navegar no site Climatempo
* Extrair:

  * Temperatura mÃ­nima
  * Temperatura mÃ¡xima
  * DescriÃ§Ã£o do clima
  * Volume de chuva
* Capturar previsÃµes para o dia seguinte
* Capturar dados reais do dia atual

O Scrapy gera o dado bruto.

Essa Ã© a parte mais crÃ­tica do projeto, pois:

* Lida com estrutura HTML
* Trata inconsistÃªncias
* Garante padronizaÃ§Ã£o mÃ­nima
* Evita falhas silenciosas

---

## 2ï¸âƒ£ Transform (PadronizaÃ§Ã£o)

ApÃ³s a coleta:

* Os dados sÃ£o tratados com Python
* Convertidos para formato estruturado
* Salvos como **CSV em string**
* Armazenados como camada Bronze

Essa etapa garante que o DBT consiga consumir dados consistentes.

---

# ğŸ¥ˆ Silver (DBT)

O DBT:

* LÃª os CSVs da Bronze
* Aplica tipagem correta
* Normaliza colunas
* Remove inconsistÃªncias
* Cria tabelas intermediÃ¡rias

SeparaÃ§Ã£o clara entre:

* `silver_climatempo_previsao`
* `silver_climatempo_dadosdia`

---

# ğŸ¥‡ Gold (DBT)

Camada analÃ­tica final:

* `gold_climatempo_dadosdia`
* `gold_climatempo_previsoes`

Estruturadas para permitir:

* Join D-1 â†’ D
* CÃ¡lculo de erro
* MÃ©tricas estatÃ­sticas
* AvaliaÃ§Ã£o por cidade
* Ranking de precisÃ£o

Essa camada jÃ¡ estÃ¡ pronta para consumo analÃ­tico.

---

# âš™ï¸ OrquestraÃ§Ã£o com Apache Airflow

O Airflow Ã© responsÃ¡vel por:

* Executar o Scrapy
* Rodar o script de Transform
* Executar DBT (run + test)
* Garantir ordem correta das etapas
* Evitar dependÃªncias quebradas
* Permitir execuÃ§Ã£o diÃ¡ria automatizada

A DAG segue lÃ³gica:

```
scrapy_task
    â†“
transform_task
    â†“
dbt_run
    â†“
dbt_test
```

Pontos fortes da orquestraÃ§Ã£o:

* ExecuÃ§Ã£o sequencial garantida
* SeparaÃ§Ã£o clara de responsabilidades
* Reprocessamento simples
* Controle de falhas

Essa parte Ã© um dos principais diferenciais do projeto.

---

# ğŸ“Š MÃ©tricas Implementadas

ComparaÃ§Ã£o entre:

* PrevisÃ£o coletada em D-1
* Dado real observado em D

MÃ©tricas calculadas:

* MAE
* RMSE
* Bias
* MAPE
* Accuracy (Choveu vs NÃ£o Choveu)
* Accuracy descriÃ§Ã£o textual
* Score composto por cidade

Ranking final ponderado:

* 50% Temperatura
* 40% Chuva
* 10% DescriÃ§Ã£o

---

# ğŸ§  Stack Utilizada

* Python
* Scrapy
* Pandas
* SQLite
* DBT
* Apache Airflow
* Streamlit
* Plotly

---

# ğŸš€ Como Executar

1. Instalar dependÃªncias

2. Subir Airflow

3. Rodar DAG

4. Abrir dashboard:

```
streamlit run dashboard/app.py
```

---

# ğŸ“Œ O que este projeto demonstra

* Engenharia de dados ponta a ponta
* Web scraping estruturado
* Arquitetura medalhÃ£o
* OrquestraÃ§Ã£o real com Airflow
* Modelagem com DBT
* MÃ©tricas de avaliaÃ§Ã£o preditiva
* ConstruÃ§Ã£o de dashboard analÃ­tico
